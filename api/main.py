import os, uuid, shutil, json
from pathlib import Path
from fastapi import FastAPI, UploadFile, File, HTTPException, Query
from fastapi.responses import JSONResponse
from redis import Redis
from rq import Queue

from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

from fastapi import Depends, Header
import secrets

REDIS_URL = os.getenv("REDIS_URL", "redis://redis:6379")
DATA_DIR  = Path(os.getenv("DATA_DIR", "/data"))
LANG_DEFAULT = "ru"
API_TOKENS = {t.strip() for t in os.getenv("API_AUTH_TOKEN", "").split(",") if t.strip()}

def require_auth(authorization: str = Header(default=None), x_api_key: str = Header(default=None)):
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ–º –ª–∏–±–æ Authorization: Bearer <token>, –ª–∏–±–æ X-API-Key: <token>.
    –ï—Å–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è API_AUTH_TOKEN –Ω–µ –∑–∞–¥–∞–Ω–∞ ‚Äî auth –≤—ã–∫–ª—é—á–µ–Ω.
    """
    if not API_TOKENS:  # auth disabled
        return
    
    # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ø—ã—Ç–∫—É –¥–æ—Å—Ç—É–ø–∞
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    # 1) Authorization: Bearer ...
    if authorization and authorization.lower().startswith("bearer "):
        token = authorization.split(" ", 1)[1].strip()
        if token in API_TOKENS:
            logger.info(f"Successful Bearer auth for token: {token[:8]}...")
            return
        else:
            logger.warning(f"Invalid Bearer token: {token[:8]}...")
    
    # 2) X-API-Key header
    if x_api_key:
        if x_api_key in API_TOKENS:
            logger.info(f"Successful X-API-Key auth for token: {x_api_key[:8]}...")
            return
        else:
            logger.warning(f"Invalid X-API-Key token: {x_api_key[:8]}...")
    
    # –õ–æ–≥–∏—Ä—É–µ–º –Ω–µ—É–¥–∞—á–Ω—É—é –ø–æ–ø—ã—Ç–∫—É
    logger.error("Unauthorized access attempt")
    
    # –∏–Ω–∞—á–µ ‚Äî 401
    from fastapi import HTTPException
    raise HTTPException(status_code=401, detail="Unauthorized")


app = FastAPI(title="Whisper+DeepSeek API (variant B)")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],           # –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ —É–∫–∞–∂–∏ —Å–≤–æ–∏ origin‚Äô—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# —Ä–∞–∑–¥–∞—ë–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã —Å –≤–µ–±-–∫–ª–∏–µ–Ω—Ç–æ–º
import os
static_dir = os.path.join(os.path.dirname(__file__), "static")
if not os.path.exists(static_dir):
    os.makedirs(static_dir, exist_ok=True)
app.mount("/app", StaticFiles(directory=static_dir, html=True), name="app")

def jobs_dir(job_id: str) -> Path:
    return DATA_DIR / "jobs" / job_id

def ensure_dirs(p: Path):
    p.mkdir(parents=True, exist_ok=True)

def enqueue_asr(job_id: str, audio_path: str, language: str):
    r = Redis.from_url(REDIS_URL)
    q = Queue("asr", connection=r)
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–∞–π–º–∞—É—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    timeout = int(os.getenv("TRANSCRIBE_TIMEOUT", "6000"))  # 10 –º–∏–Ω—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    q.enqueue(
        "tasks.transcribe.transcribe_job", 
        job_id, 
        audio_path, 
        language,
        job_timeout=timeout,
        result_ttl=timeout * 2  # –†–µ–∑—É–ª—å—Ç–∞—Ç —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ 2 —Ä–∞–∑–∞ –¥–æ–ª—å—à–µ —Ç–∞–π–º–∞—É—Ç–∞
    )

@app.get("/healthz")
def healthz(_auth=Depends(require_auth)):
    return {"status": "ok"}

@app.get("/auth/check")
def check_auth(_auth=Depends(require_auth)):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º —Ç–æ–∫–µ–Ω–µ"""
    return {
        "status": "authenticated",
        "message": "–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞",
        "auth_enabled": bool(API_TOKENS)
    }

@app.get("/stats")
def get_stats(_auth=Depends(require_auth)):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    import os
    from pathlib import Path
    
    jobs_dir = DATA_DIR / "jobs"
    if not jobs_dir.exists():
        return {"total_jobs": 0, "completed_jobs": 0, "processing_jobs": 0}
    
    total_jobs = 0
    completed_jobs = 0
    processing_jobs = 0
    
    for job_dir in jobs_dir.iterdir():
        if job_dir.is_dir():
            total_jobs += 1
            if (job_dir / "summary.json").exists():
                completed_jobs += 1
            elif (job_dir / "transcript.json").exists():
                processing_jobs += 1
    
    return {
        "total_jobs": total_jobs,
        "completed_jobs": completed_jobs,
        "processing_jobs": processing_jobs,
        "queued_jobs": total_jobs - completed_jobs - processing_jobs
    }

@app.post("/upload")
async def upload(
    file: UploadFile = File(...),
    language: str = Query(LANG_DEFAULT),
    _auth=Depends(require_auth),                   # üîê –∑–∞—â–∏—Ç–∞
):
    job_id = str(uuid.uuid4())
    jdir = jobs_dir(job_id)
    ensure_dirs(jdir)

    suffix = Path(file.filename).suffix or ".wav"
    audio_path = jdir / f"input{suffix}"

    with audio_path.open("wb") as f:
        shutil.copyfileobj(file.file, f)

    # –ü–æ–º–µ—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    meta = {"job_id": job_id, "filename": file.filename, "language": language}
    (jdir / "meta.json").write_text(json.dumps(meta, ensure_ascii=False, indent=2), "utf-8")

    enqueue_asr(job_id, str(audio_path), language)
    return {"job_id": job_id, "status": "queued"}

@app.get("/status/{job_id}")
def status(job_id: str, _auth=Depends(require_auth)): 
    jdir = jobs_dir(job_id)
    if not jdir.exists():
        raise HTTPException(404, "job not found")

    transcript = jdir / "transcript.json"
    summary    = jdir / "summary.json"
    if summary.exists():
        return {"job_id": job_id, "status": "done"}
    if transcript.exists():
        return {"job_id": job_id, "status": "transcribed_waiting_summary"}
    return {"job_id": job_id, "status": "processing"}

@app.get("/result/{job_id}")
def result(job_id: str, _auth=Depends(require_auth)): 
    jdir = jobs_dir(job_id)
    if not jdir.exists():
        raise HTTPException(404, "job not found")
    
    transcript = jdir / "transcript.json"
    summary = jdir / "summary.json"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –≥–æ—Ç–æ–≤
    if not transcript.exists():
        return JSONResponse({"error": "transcript_not_ready"}, status_code=202)
    
    out = {"job_id": job_id}
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
    try:
        out["transcript"] = json.loads(transcript.read_text("utf-8"))
    except Exception as e:
        return JSONResponse({"error": f"transcript_read_error: {str(e)}"}, status_code=500)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∞–º–º–∞—Ä–∏, –µ—Å–ª–∏ –æ–Ω–æ –≥–æ—Ç–æ–≤–æ
    if summary.exists():
        try:
            summary_data = json.loads(summary.read_text("utf-8"))
            out["summary"] = summary_data
        except Exception as e:
            # –ï—Å–ª–∏ —Å–∞–º–º–∞—Ä–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
            out["summary_error"] = f"summary_read_error: {str(e)}"
    
    return out

@app.get("/history")
def get_history(_auth=Depends(require_auth)):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –≤—Å–µ—Ö –∑–∞–¥–∞—á —Å –∏—Ö —Å—Ç–∞—Ç—É—Å–∞–º–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
    jobs_dir_path = DATA_DIR / "jobs"
    if not jobs_dir_path.exists():
        return {"jobs": []}
    
    jobs = []
    for job_dir in jobs_dir_path.iterdir():
        if not job_dir.is_dir():
            continue
            
        job_id = job_dir.name
        meta_file = job_dir / "meta.json"
        transcript_file = job_dir / "transcript.json"
        summary_file = job_dir / "summary.json"
        
        job_info = {
            "job_id": job_id,
            "status": "unknown"
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        if summary_file.exists():
            job_info["status"] = "done"
        elif transcript_file.exists():
            job_info["status"] = "transcribed_waiting_summary"
        else:
            job_info["status"] = "processing"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if meta_file.exists():
            try:
                meta = json.loads(meta_file.read_text("utf-8"))
                job_info.update(meta)
            except:
                job_info["filename"] = "unknown"
                job_info["language"] = "unknown"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
        job_info["has_transcript"] = transcript_file.exists()
        job_info["has_summary"] = summary_file.exists()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤
        if transcript_file.exists():
            job_info["transcript_size"] = transcript_file.stat().st_size
        if summary_file.exists():
            job_info["summary_size"] = summary_file.stat().st_size
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è (–∏–∑ –∏–º–µ–Ω–∏ –ø–∞–ø–∫–∏ –∏–ª–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –≤—Ä–µ–º—è –∏–∑ UUID
            import time
            timestamp = int(job_id.split('-')[0], 16) / 10000000 - 11644473600
            job_info["created_at"] = timestamp
        except:
            job_info["created_at"] = None
        
        jobs.append(job_info)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
    jobs.sort(key=lambda x: x.get("created_at", 0) or 0, reverse=True)
    
    return {"jobs": jobs}

@app.get("/history/{job_id}")
def get_job_history(job_id: str, _auth=Depends(require_auth)):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–µ"""
    jdir = jobs_dir(job_id)
    if not jdir.exists():
        raise HTTPException(404, "job not found")
    
    job_info = {"job_id": job_id}
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    meta_file = jdir / "meta.json"
    if meta_file.exists():
        try:
            meta = json.loads(meta_file.read_text("utf-8"))
            job_info.update(meta)
        except:
            pass
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
    transcript_file = jdir / "transcript.json"
    if transcript_file.exists():
        try:
            transcript = json.loads(transcript_file.read_text("utf-8"))
            job_info["transcript"] = transcript
        except:
            job_info["transcript_error"] = "Failed to read transcript"
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∞–º–º–∞—Ä–∏
    summary_file = jdir / "summary.json"
    if summary_file.exists():
        try:
            summary = json.loads(summary_file.read_text("utf-8"))
            job_info["summary"] = summary
        except:
            job_info["summary_error"] = "Failed to read summary"
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
    if summary_file.exists():
        job_info["status"] = "done"
    elif transcript_file.exists():
        job_info["status"] = "transcribed_waiting_summary"
    else:
        job_info["status"] = "processing"
    
    return job_info

@app.delete("/history/{job_id}")
def delete_job(job_id: str, _auth=Depends(require_auth)):
    """–£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –∏ –≤—Å–µ—Ö —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    jdir = jobs_dir(job_id)
    if not jdir.exists():
        raise HTTPException(404, "job not found")
    
    try:
        import shutil
        shutil.rmtree(jdir)
        return {"message": "Job deleted successfully"}
    except Exception as e:
        raise HTTPException(500, f"Failed to delete job: {str(e)}")
